<h1 align="center">ğŸ”¥ Spark JSON Data Processing Notebook</h1>
<p align="center">
  A simple and clean Apache Spark project for reading, transforming, and analyzing JSON files using PySpark.
</p>

---

## ğŸ“Œ Overview

This project demonstrates **how to use PySpark to read JSON data**, handle nested fields, explode metadata arrays, and inspect schema inside a Databricks or Spark notebook environment.

The notebook performs:

- Reading multiline JSON files  
- Inferring schema automatically  
- Exploding nested structures  
- Selecting nested keys/values  
- Displaying timestamps  
- Printing the complete schema  

---

## ğŸ“‚ File Included

This file contains all PySpark code cells required for JSON processing.

---

## ğŸš€ Features

- ğŸ“¥ **Load JSON files** using Spark DataFrame reader  
- ğŸ“‘ **Multiline JSON parsing**  
- ğŸ§© **Explode nested `metadata` arrays**  
- ğŸ” **Select specific nested fields (`key`, `value`)**  
- ğŸ•’ **Timestamp extraction**  
- ğŸ—ï¸ **Schema printing for understanding structure**  
- ğŸ–¥ï¸ **Notebook-friendly display commands (`display()`)**

---

## ğŸ› ï¸ Technologies Used

- **Python**
- **Apache Spark / PySpark**
- **Databricks Notebook Environment**
- **JSON Dataset**

---
## ğŸ¤ Contributing

Pull requests are welcome!
If you'd like to improve this notebook or convert it into a full ETL pipeline, feel free to contribute.

ğŸ‘¤ Author

Zain Ul Abideen Alvi



